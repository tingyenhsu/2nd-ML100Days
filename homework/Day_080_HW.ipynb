{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "#     out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    out = keras.layers.Dense(units=output_units, activation=\"sigmoid\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "LEARNING_RATE = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 512\n",
    "MOMENTUM = 0.85\n",
    "\n",
    "#---Adagrad\n",
    "decay=1e-7\n",
    "epsilon=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,001,546\n",
      "Trainable params: 2,001,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 2.0888 - acc: 0.2448 - val_loss: 1.9660 - val_acc: 0.2999\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 1.8400 - acc: 0.3439 - val_loss: 1.7730 - val_acc: 0.3772\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.7393 - acc: 0.3827 - val_loss: 1.6699 - val_acc: 0.4117\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.6633 - acc: 0.4110 - val_loss: 1.6088 - val_acc: 0.4306\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.6087 - acc: 0.4323 - val_loss: 1.6158 - val_acc: 0.4247\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.5650 - acc: 0.4487 - val_loss: 1.5823 - val_acc: 0.4256\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.5286 - acc: 0.4584 - val_loss: 1.5148 - val_acc: 0.4593\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.4908 - acc: 0.4708 - val_loss: 1.5057 - val_acc: 0.4640\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 14s 284us/step - loss: 1.4709 - acc: 0.4800 - val_loss: 1.4636 - val_acc: 0.4811\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 1.4329 - acc: 0.4927 - val_loss: 1.4960 - val_acc: 0.4688\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.4069 - acc: 0.5014 - val_loss: 1.4507 - val_acc: 0.4822\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 14s 283us/step - loss: 1.3866 - acc: 0.5109 - val_loss: 1.4183 - val_acc: 0.4936\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 14s 284us/step - loss: 1.3594 - acc: 0.5193 - val_loss: 1.4372 - val_acc: 0.4849\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3372 - acc: 0.5256 - val_loss: 1.3987 - val_acc: 0.4949\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 14s 281us/step - loss: 1.3152 - acc: 0.5340 - val_loss: 1.4968 - val_acc: 0.4670\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 1.2953 - acc: 0.5405 - val_loss: 1.4701 - val_acc: 0.4765\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.2825 - acc: 0.5463 - val_loss: 1.4201 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.2665 - acc: 0.5545 - val_loss: 1.3542 - val_acc: 0.5201\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 15s 299us/step - loss: 1.2441 - acc: 0.5591 - val_loss: 1.3946 - val_acc: 0.5038\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.2255 - acc: 0.5645 - val_loss: 1.4055 - val_acc: 0.5008\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.2093 - acc: 0.5749 - val_loss: 1.3956 - val_acc: 0.4985\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 1.1845 - acc: 0.5826 - val_loss: 1.3528 - val_acc: 0.5202\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 1.1629 - acc: 0.5914 - val_loss: 1.3655 - val_acc: 0.5170\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 1.1557 - acc: 0.5910 - val_loss: 1.3675 - val_acc: 0.5162\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.1385 - acc: 0.5985 - val_loss: 1.3559 - val_acc: 0.5205\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.1128 - acc: 0.6080 - val_loss: 1.3134 - val_acc: 0.5329\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.1035 - acc: 0.6101 - val_loss: 1.3014 - val_acc: 0.5415\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 1.0838 - acc: 0.6188 - val_loss: 1.3562 - val_acc: 0.5267\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 15s 290us/step - loss: 1.0618 - acc: 0.6261 - val_loss: 1.5031 - val_acc: 0.4960\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.0599 - acc: 0.6270 - val_loss: 1.3874 - val_acc: 0.5185\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.0298 - acc: 0.6383 - val_loss: 1.3415 - val_acc: 0.5379\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 1.0130 - acc: 0.6415 - val_loss: 1.4196 - val_acc: 0.5152\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 0.9977 - acc: 0.6501 - val_loss: 1.3435 - val_acc: 0.5276\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 0.9772 - acc: 0.6568 - val_loss: 1.4143 - val_acc: 0.5178\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 14s 289us/step - loss: 0.9719 - acc: 0.6608 - val_loss: 1.3974 - val_acc: 0.5229\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.9521 - acc: 0.6656 - val_loss: 1.3972 - val_acc: 0.5288\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.9309 - acc: 0.6729 - val_loss: 1.3964 - val_acc: 0.5320\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 14s 283us/step - loss: 0.9218 - acc: 0.6740 - val_loss: 1.3532 - val_acc: 0.5387\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 14s 282us/step - loss: 0.8901 - acc: 0.6875 - val_loss: 1.3605 - val_acc: 0.5440\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.8862 - acc: 0.6871 - val_loss: 1.3712 - val_acc: 0.5251\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.8714 - acc: 0.6950 - val_loss: 1.4526 - val_acc: 0.5234\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: nan - acc: 0.2392 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 15s 296us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Experiment with LR = 0.001000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,001,546\n",
      "Trainable params: 2,001,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 2.2807 - acc: 0.1328 - val_loss: 2.2564 - val_acc: 0.1650\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 2.2327 - acc: 0.1827 - val_loss: 2.2053 - val_acc: 0.2043\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 15s 299us/step - loss: 2.1735 - acc: 0.2092 - val_loss: 2.1346 - val_acc: 0.2194\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 2.0939 - acc: 0.2284 - val_loss: 2.0490 - val_acc: 0.2431\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 2.0137 - acc: 0.2642 - val_loss: 1.9756 - val_acc: 0.2954\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.9496 - acc: 0.3007 - val_loss: 1.9225 - val_acc: 0.3217\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 14s 289us/step - loss: 1.9030 - acc: 0.3269 - val_loss: 1.8830 - val_acc: 0.3321\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.8662 - acc: 0.3399 - val_loss: 1.8507 - val_acc: 0.3468\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 1.8372 - acc: 0.3522 - val_loss: 1.8272 - val_acc: 0.3555\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 1.8131 - acc: 0.3605 - val_loss: 1.8009 - val_acc: 0.3701\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.7915 - acc: 0.3688 - val_loss: 1.7848 - val_acc: 0.3729\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.7725 - acc: 0.3778 - val_loss: 1.7723 - val_acc: 0.3684\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 1.7545 - acc: 0.3829 - val_loss: 1.7459 - val_acc: 0.3875\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.7389 - acc: 0.3901 - val_loss: 1.7356 - val_acc: 0.3892\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 1.7235 - acc: 0.3954 - val_loss: 1.7207 - val_acc: 0.3901\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.7091 - acc: 0.3992 - val_loss: 1.7065 - val_acc: 0.3982\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.6971 - acc: 0.4038 - val_loss: 1.6953 - val_acc: 0.4048\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.6849 - acc: 0.4075 - val_loss: 1.6871 - val_acc: 0.4139\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.6732 - acc: 0.4131 - val_loss: 1.6843 - val_acc: 0.4101\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.6622 - acc: 0.4188 - val_loss: 1.6607 - val_acc: 0.4177\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.6507 - acc: 0.4215 - val_loss: 1.6543 - val_acc: 0.4198\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 1.6402 - acc: 0.4259 - val_loss: 1.6358 - val_acc: 0.4256\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 1.6319 - acc: 0.4298 - val_loss: 1.6319 - val_acc: 0.4307\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 1.6207 - acc: 0.4348 - val_loss: 1.6193 - val_acc: 0.4356\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 26s 512us/step - loss: 1.6124 - acc: 0.4364 - val_loss: 1.6178 - val_acc: 0.4324\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 1.6030 - acc: 0.4399 - val_loss: 1.6173 - val_acc: 0.4317\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 27s 540us/step - loss: 1.5957 - acc: 0.4409 - val_loss: 1.6134 - val_acc: 0.4359\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 1.5867 - acc: 0.4461 - val_loss: 1.5980 - val_acc: 0.4384\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 1.5784 - acc: 0.4495 - val_loss: 1.5937 - val_acc: 0.4379\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 1.5707 - acc: 0.4516 - val_loss: 1.5768 - val_acc: 0.4456\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 27s 540us/step - loss: 1.5638 - acc: 0.4532 - val_loss: 1.5692 - val_acc: 0.4497\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 26s 526us/step - loss: 1.5568 - acc: 0.4567 - val_loss: 1.5669 - val_acc: 0.4472\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 27s 534us/step - loss: 1.5488 - acc: 0.4582 - val_loss: 1.5594 - val_acc: 0.4566\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 1.5412 - acc: 0.4609 - val_loss: 1.5697 - val_acc: 0.4502\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 1.5332 - acc: 0.4635 - val_loss: 1.5507 - val_acc: 0.4566\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 27s 542us/step - loss: 1.5281 - acc: 0.4661 - val_loss: 1.5431 - val_acc: 0.4604\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 26s 527us/step - loss: 1.5221 - acc: 0.4685 - val_loss: 1.5426 - val_acc: 0.4575\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 26s 522us/step - loss: 1.5139 - acc: 0.4711 - val_loss: 1.5351 - val_acc: 0.4586\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 1.5078 - acc: 0.4729 - val_loss: 1.5354 - val_acc: 0.4626\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 27s 540us/step - loss: 1.5010 - acc: 0.4751 - val_loss: 1.5240 - val_acc: 0.4640\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 27s 537us/step - loss: 1.4949 - acc: 0.4768 - val_loss: 1.5196 - val_acc: 0.4597\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 26s 525us/step - loss: 1.4886 - acc: 0.4780 - val_loss: 1.5189 - val_acc: 0.4652\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 1.4831 - acc: 0.4816 - val_loss: 1.5147 - val_acc: 0.4658\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 1.4760 - acc: 0.4814 - val_loss: 1.5028 - val_acc: 0.4689\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 26s 522us/step - loss: 1.4701 - acc: 0.4845 - val_loss: 1.5091 - val_acc: 0.4651\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 25s 508us/step - loss: 1.4637 - acc: 0.4866 - val_loss: 1.4897 - val_acc: 0.4725\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 1.4589 - acc: 0.4910 - val_loss: 1.4912 - val_acc: 0.4728\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 1.4509 - acc: 0.4906 - val_loss: 1.5026 - val_acc: 0.4694\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 36s 722us/step - loss: 1.4472 - acc: 0.4917 - val_loss: 1.4798 - val_acc: 0.4752\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 40s 799us/step - loss: 1.4390 - acc: 0.4951 - val_loss: 1.4766 - val_acc: 0.4820\n",
      "Experiment with LR = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,001,546\n",
      "Trainable params: 2,001,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 40s 795us/step - loss: 2.3225 - acc: 0.1181 - val_loss: 2.3103 - val_acc: 0.1228\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 2.3039 - acc: 0.1248 - val_loss: 2.2978 - val_acc: 0.1344\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 38s 763us/step - loss: 2.2936 - acc: 0.1338 - val_loss: 2.2889 - val_acc: 0.1421\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 2.2855 - acc: 0.1415 - val_loss: 2.2814 - val_acc: 0.1469\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 2.2784 - acc: 0.1484 - val_loss: 2.2746 - val_acc: 0.1531\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 2.2718 - acc: 0.1525 - val_loss: 2.2681 - val_acc: 0.1575\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 40s 794us/step - loss: 2.2653 - acc: 0.1584 - val_loss: 2.2616 - val_acc: 0.1641\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 2.2588 - acc: 0.1645 - val_loss: 2.2551 - val_acc: 0.1742\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 2.2522 - acc: 0.1716 - val_loss: 2.2485 - val_acc: 0.1854\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 40s 802us/step - loss: 2.2454 - acc: 0.1822 - val_loss: 2.2416 - val_acc: 0.1950\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 2.2383 - acc: 0.1909 - val_loss: 2.2343 - val_acc: 0.2028\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 40s 799us/step - loss: 2.2308 - acc: 0.2013 - val_loss: 2.2266 - val_acc: 0.2131\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 2.2229 - acc: 0.2084 - val_loss: 2.2185 - val_acc: 0.2209\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 2.2146 - acc: 0.2157 - val_loss: 2.2100 - val_acc: 0.2259\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 38s 764us/step - loss: 2.2057 - acc: 0.2229 - val_loss: 2.2009 - val_acc: 0.2329\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 40s 792us/step - loss: 2.1964 - acc: 0.2287 - val_loss: 2.1913 - val_acc: 0.2367\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 38s 755us/step - loss: 2.1866 - acc: 0.2346 - val_loss: 2.1813 - val_acc: 0.2424\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 39s 784us/step - loss: 2.1763 - acc: 0.2420 - val_loss: 2.1708 - val_acc: 0.2467\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 39s 770us/step - loss: 2.1656 - acc: 0.2467 - val_loss: 2.1599 - val_acc: 0.2513\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 40s 791us/step - loss: 2.1545 - acc: 0.2512 - val_loss: 2.1487 - val_acc: 0.2551\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 2.1430 - acc: 0.2544 - val_loss: 2.1371 - val_acc: 0.2580\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 2.1311 - acc: 0.2572 - val_loss: 2.1252 - val_acc: 0.2617\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 39s 770us/step - loss: 2.1191 - acc: 0.2615 - val_loss: 2.1131 - val_acc: 0.2617\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 2.1069 - acc: 0.2634 - val_loss: 2.1011 - val_acc: 0.2650\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 36s 726us/step - loss: 2.0949 - acc: 0.2658 - val_loss: 2.0890 - val_acc: 0.2661\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 38s 752us/step - loss: 2.0830 - acc: 0.2689 - val_loss: 2.0772 - val_acc: 0.2691\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 38s 767us/step - loss: 2.0714 - acc: 0.2721 - val_loss: 2.0658 - val_acc: 0.2738\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 2.0600 - acc: 0.2747 - val_loss: 2.0546 - val_acc: 0.2742\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 2.0490 - acc: 0.2775 - val_loss: 2.0440 - val_acc: 0.2758\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 2.0385 - acc: 0.2795 - val_loss: 2.0335 - val_acc: 0.2802\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 2.0284 - acc: 0.2826 - val_loss: 2.0237 - val_acc: 0.2827\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 2.0187 - acc: 0.2865 - val_loss: 2.0144 - val_acc: 0.2835\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 40s 793us/step - loss: 2.0094 - acc: 0.2873 - val_loss: 2.0053 - val_acc: 0.2855\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 2.0007 - acc: 0.2903 - val_loss: 1.9969 - val_acc: 0.2894\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 45s 896us/step - loss: 1.9922 - acc: 0.2932 - val_loss: 1.9889 - val_acc: 0.2914\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 43s 855us/step - loss: 1.9843 - acc: 0.2957 - val_loss: 1.9813 - val_acc: 0.2957\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 1.9768 - acc: 0.2987 - val_loss: 1.9739 - val_acc: 0.2968\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 1.9697 - acc: 0.3015 - val_loss: 1.9672 - val_acc: 0.2987\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 38s 753us/step - loss: 1.9629 - acc: 0.3035 - val_loss: 1.9607 - val_acc: 0.3023\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.9563 - acc: 0.3070 - val_loss: 1.9545 - val_acc: 0.3043\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 38s 764us/step - loss: 1.9503 - acc: 0.3094 - val_loss: 1.9485 - val_acc: 0.3075\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 1.9443 - acc: 0.3096 - val_loss: 1.9429 - val_acc: 0.3121\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 38s 762us/step - loss: 1.9387 - acc: 0.3144 - val_loss: 1.9376 - val_acc: 0.3105\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 1.9334 - acc: 0.3165 - val_loss: 1.9322 - val_acc: 0.3144\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 32s 639us/step - loss: 1.9281 - acc: 0.3180 - val_loss: 1.9272 - val_acc: 0.3181\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 1.9232 - acc: 0.3210 - val_loss: 1.9225 - val_acc: 0.3236\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 27s 533us/step - loss: 1.9184 - acc: 0.3241 - val_loss: 1.9179 - val_acc: 0.3244\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 27s 530us/step - loss: 1.9138 - acc: 0.3263 - val_loss: 1.9134 - val_acc: 0.3274\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 27s 538us/step - loss: 1.9092 - acc: 0.3311 - val_loss: 1.9093 - val_acc: 0.3282\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 1.9051 - acc: 0.3315 - val_loss: 1.9052 - val_acc: 0.3335\n",
      "Experiment with LR = 0.000010\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,001,546\n",
      "Trainable params: 2,001,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 2.3126 - acc: 0.0799 - val_loss: 2.3130 - val_acc: 0.0815\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 2.3117 - acc: 0.0807 - val_loss: 2.3120 - val_acc: 0.0825\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 2.3107 - acc: 0.0814 - val_loss: 2.3111 - val_acc: 0.0830\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 27s 543us/step - loss: 2.3098 - acc: 0.0827 - val_loss: 2.3102 - val_acc: 0.0844\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 2.3089 - acc: 0.0837 - val_loss: 2.3093 - val_acc: 0.0867\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 2.3081 - acc: 0.0847 - val_loss: 2.3084 - val_acc: 0.0880\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 2.3073 - acc: 0.0860 - val_loss: 2.3076 - val_acc: 0.0899\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 28s 569us/step - loss: 2.3065 - acc: 0.0879 - val_loss: 2.3068 - val_acc: 0.0919\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 27s 543us/step - loss: 2.3057 - acc: 0.0891 - val_loss: 2.3060 - val_acc: 0.0938\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 2.3049 - acc: 0.0904 - val_loss: 2.3052 - val_acc: 0.0946\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 2.3042 - acc: 0.0917 - val_loss: 2.3045 - val_acc: 0.0968\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 2.3034 - acc: 0.0929 - val_loss: 2.3038 - val_acc: 0.0991\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 28s 562us/step - loss: 2.3027 - acc: 0.0948 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 590us/step - loss: 2.3020 - acc: 0.0958 - val_loss: 2.3024 - val_acc: 0.1015\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 2.3013 - acc: 0.0979 - val_loss: 2.3017 - val_acc: 0.1036\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 2.3007 - acc: 0.0993 - val_loss: 2.3010 - val_acc: 0.1039\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 2.3000 - acc: 0.1010 - val_loss: 2.3004 - val_acc: 0.1049\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 2.2994 - acc: 0.1023 - val_loss: 2.2997 - val_acc: 0.1055\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 2.2988 - acc: 0.1033 - val_loss: 2.2991 - val_acc: 0.1073\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 2.2982 - acc: 0.1050 - val_loss: 2.2985 - val_acc: 0.1086\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 2.2975 - acc: 0.1061 - val_loss: 2.2979 - val_acc: 0.1088\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 2.2969 - acc: 0.1074 - val_loss: 2.2973 - val_acc: 0.1097\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 2.2964 - acc: 0.1080 - val_loss: 2.2967 - val_acc: 0.1106\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 26s 518us/step - loss: 2.2958 - acc: 0.1090 - val_loss: 2.2961 - val_acc: 0.1110\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 2.2952 - acc: 0.1102 - val_loss: 2.2955 - val_acc: 0.1110\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 27s 538us/step - loss: 2.2946 - acc: 0.1109 - val_loss: 2.2949 - val_acc: 0.1117\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 2.2941 - acc: 0.1117 - val_loss: 2.2944 - val_acc: 0.1115\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 2.2935 - acc: 0.1120 - val_loss: 2.2938 - val_acc: 0.1118\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 2.2930 - acc: 0.1124 - val_loss: 2.2933 - val_acc: 0.1123\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 27s 533us/step - loss: 2.2924 - acc: 0.1127 - val_loss: 2.2927 - val_acc: 0.1131\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 2.2919 - acc: 0.1129 - val_loss: 2.2922 - val_acc: 0.1133\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 2.2913 - acc: 0.1132 - val_loss: 2.2917 - val_acc: 0.1139\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 2.2908 - acc: 0.1137 - val_loss: 2.2911 - val_acc: 0.1141\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 2.2903 - acc: 0.1141 - val_loss: 2.2906 - val_acc: 0.1138\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 2.2898 - acc: 0.1142 - val_loss: 2.2901 - val_acc: 0.1134\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 2.2892 - acc: 0.1145 - val_loss: 2.2896 - val_acc: 0.1140\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 32s 648us/step - loss: 2.2887 - acc: 0.1147 - val_loss: 2.2891 - val_acc: 0.1148\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 27s 534us/step - loss: 2.2882 - acc: 0.1149 - val_loss: 2.2886 - val_acc: 0.1149\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 26s 522us/step - loss: 2.2877 - acc: 0.1151 - val_loss: 2.2881 - val_acc: 0.1150\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 2.2872 - acc: 0.1153 - val_loss: 2.2876 - val_acc: 0.1149\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 2.2867 - acc: 0.1155 - val_loss: 2.2870 - val_acc: 0.1150\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 27s 549us/step - loss: 2.2862 - acc: 0.1156 - val_loss: 2.2865 - val_acc: 0.1151\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 26s 522us/step - loss: 2.2857 - acc: 0.1159 - val_loss: 2.2860 - val_acc: 0.1153\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 2.2852 - acc: 0.1161 - val_loss: 2.2855 - val_acc: 0.1154\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 2.2847 - acc: 0.1163 - val_loss: 2.2850 - val_acc: 0.1159\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 27s 545us/step - loss: 2.2842 - acc: 0.1168 - val_loss: 2.2845 - val_acc: 0.1158\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 29s 579us/step - loss: 2.2837 - acc: 0.1170 - val_loss: 2.2840 - val_acc: 0.1157\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 28s 566us/step - loss: 2.2832 - acc: 0.1170 - val_loss: 2.2835 - val_acc: 0.1157\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 29s 583us/step - loss: 2.2827 - acc: 0.1171 - val_loss: 2.2830 - val_acc: 0.1160\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 591us/step - loss: 2.2822 - acc: 0.1173 - val_loss: 2.2825 - val_acc: 0.1161\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "建立你的訓練與實驗迴圈並蒐集資料\n",
    "\"\"\"\n",
    "\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "#     optimizer = keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=decay)\n",
    "    optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzQLBGGMMYIFgjDHG7f8AOvcMzdAnAFQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 以視覺畫方式檢視訓練過程\n",
    "import matplotlib.pyplot as plt\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\1709091\\Documents\\GitHub\\2nd-ML100Days\\homework\\saved_models\\SGD \n",
      "10000/10000 [==============================] - 5s 513us/step\n",
      "Test loss: 2.282527448272705\n",
      "Test accuracy: 0.1161\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SGD' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model. \n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adagrad\n",
    "# Test loss: 2.0508104572296144\n",
    "# Test accuracy: 0.3032\n",
    "\n",
    "# SGD\n",
    "# Test loss: 2.2290771209716795\n",
    "# Test accuracy: 0.2089"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
